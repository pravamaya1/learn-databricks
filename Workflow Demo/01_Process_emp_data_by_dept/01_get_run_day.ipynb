{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a58171e5-cf65-48ba-83d7-6ab191be766d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ISO date format - (yyyy-MM-ddTHH:mm:ss)\n",
    "#Read date as input and get the day of the week- lie Sun, Mon, Tue, Wed, Thu, Fri, Sat\n",
    "#Create input_date widget\n",
    "\n",
    "dbutils.widgets.text(\"input_date\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7f1853-e908-4df1-a620-214bf6e16e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "_input_date=dbutils.widgets.get(\"input_date\")\n",
    "print(_input_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce1a85c9-3d9c-4840-a7d1-6491c3611bc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Format the input_date to extract the day of the week\n",
    "# Set conf to LEGACY to support datetime patterns\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, date_format\n",
    "\n",
    "# Define the input date string\n",
    "_input_date = \"2025-01-28T14:30:00\"\n",
    "\n",
    "# Create a DataFrame with the input date\n",
    "df = spark.createDataFrame([(_input_date,)], [\"input_date\"])\n",
    "\n",
    "# Use to_timestamp to parse the date and date_format to extract the day\n",
    "_input_day = df.select(date_format(to_timestamp(\"input_date\", \"yyyy-MM-dd'T'HH:mm:ss\"), \"E\").alias(\"day_of_week\")).collect()\n",
    "\n",
    "# Print the result\n",
    "print(_input_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f98e27fd-a54d-49ca-8415-7c424ed26be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Export the day of eek using taskValue to use in next week\n",
    "\n",
    "dbutils.jobs.taskValues.set(\"inout_day\",_input_day)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_get_run_day",
   "widgets": {
    "input_date": {
     "currentValue": " ",
     "nuid": "2d874ec8-4bbf-4aff-b4b7-15accb3af179",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": " ",
      "label": null,
      "name": "input_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": " ",
      "label": null,
      "name": "input_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
